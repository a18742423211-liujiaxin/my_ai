#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•çº¿æ€§å›å½’ç¤ºä¾‹
===============

è¿™ä¸ªæ–‡ä»¶å°†æ•™æ‚¨ï¼š
1. ä»€ä¹ˆæ˜¯çº¿æ€§å›å½’
2. å¦‚ä½•ç”Ÿæˆè®­ç»ƒæ•°æ®
3. å¦‚ä½•å®šä¹‰æ¨¡å‹å’ŒæŸå¤±å‡½æ•°
4. å¦‚ä½•è®­ç»ƒæ¨¡å‹
5. å¦‚ä½•å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹

è¿™æ˜¯æœºå™¨å­¦ä¹ çš„"Hello World"ï¼
"""

import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import numpy as np

def main():
    print("ğŸš€ æ¬¢è¿æ¥åˆ°çº¿æ€§å›å½’å­¦ä¹ ï¼")
    print("=" * 50)
    
    # ========================================
    # ç¬¬1éƒ¨åˆ†ï¼šç†è§£çº¿æ€§å›å½’
    # ========================================
    print("\nğŸ“š ç¬¬1éƒ¨åˆ†ï¼šä»€ä¹ˆæ˜¯çº¿æ€§å›å½’ï¼Ÿ")
    print("-" * 30)
    print("çº¿æ€§å›å½’å°±æ˜¯æ‰¾ä¸€æ¡ç›´çº¿æ¥æ‹Ÿåˆæ•°æ®ç‚¹")
    print("æ¯”å¦‚ï¼šæˆ¿å­é¢ç§¯ -> æˆ¿ä»·ï¼Œå­¦ä¹ æ—¶é—´ -> è€ƒè¯•æˆç»©")
    print("å…¬å¼ï¼šy = w * x + b")
    print("å…¶ä¸­ï¼šwæ˜¯æƒé‡(æ–œç‡)ï¼Œbæ˜¯åç½®(æˆªè·)")
    
    # ========================================
    # ç¬¬2éƒ¨åˆ†ï¼šç”Ÿæˆè®­ç»ƒæ•°æ®
    # ========================================
    print("\nğŸ“š ç¬¬2éƒ¨åˆ†ï¼šç”Ÿæˆè®­ç»ƒæ•°æ®")
    print("-" * 30)
    
    # è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œç»“æœä¸€è‡´
    torch.manual_seed(42)
    
    # ç”Ÿæˆä¸€äº›ç¤ºä¾‹æ•°æ®ï¼šy = 2 * x + 1 + å™ªå£°
    # æ¯”å¦‚ï¼šxæ˜¯æˆ¿å­é¢ç§¯ï¼Œyæ˜¯æˆ¿ä»·
    true_w = 2.0  # çœŸå®çš„æƒé‡
    true_b = 1.0  # çœŸå®çš„åç½®
    
    # ç”Ÿæˆ100ä¸ªæ•°æ®ç‚¹
    n_samples = 100
    x = torch.randn(n_samples, 1) * 2  # xæ˜¯ä»-4åˆ°4çš„éšæœºæ•°
    noise = torch.randn(n_samples, 1) * 0.5  # æ·»åŠ ä¸€äº›å™ªå£°è®©æ•°æ®æ›´çœŸå®
    y = true_w * x + true_b + noise  # çœŸå®çš„å…³ç³»åŠ ä¸Šå™ªå£°
    
    print(f"ç”Ÿæˆäº† {n_samples} ä¸ªæ•°æ®ç‚¹")
    print(f"çœŸå®å…³ç³»ï¼šy = {true_w} * x + {true_b} + å™ªå£°")
    print(f"æ•°æ®èŒƒå›´ï¼šxä»{x.min():.2f}åˆ°{x.max():.2f}")
    print(f"æ•°æ®èŒƒå›´ï¼šyä»{y.min():.2f}åˆ°{y.max():.2f}")
    
    # ========================================
    # ç¬¬3éƒ¨åˆ†ï¼šå®šä¹‰æ¨¡å‹
    # ========================================
    print("\nğŸ“š ç¬¬3éƒ¨åˆ†ï¼šå®šä¹‰çº¿æ€§å›å½’æ¨¡å‹")
    print("-" * 30)
    
    # åœ¨PyTorchä¸­ï¼Œnn.Linearå°±æ˜¯çº¿æ€§å±‚ï¼Œå®ƒä¼šè‡ªåŠ¨å­¦ä¹ wå’Œb
    model = nn.Linear(1, 1)  # è¾“å…¥1ä¸ªç‰¹å¾ï¼Œè¾“å‡º1ä¸ªå€¼
    
    # æŸ¥çœ‹æ¨¡å‹çš„åˆå§‹å‚æ•°
    print("æ¨¡å‹çš„åˆå§‹å‚æ•°ï¼š")
    for name, param in model.named_parameters():
        print(f"{name}: {param.data}")
    
    # ========================================
    # ç¬¬4éƒ¨åˆ†ï¼šå®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    # ========================================
    print("\nğŸ“š ç¬¬4éƒ¨åˆ†ï¼šå®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨")
    print("-" * 30)
    
    # æŸå¤±å‡½æ•°ï¼šå‡æ–¹è¯¯å·®(MSE)ï¼Œè¡¡é‡é¢„æµ‹å€¼å’ŒçœŸå®å€¼çš„å·®è·
    criterion = nn.MSELoss()
    print("æŸå¤±å‡½æ•°ï¼šå‡æ–¹è¯¯å·®(MSE)")
    
    # ä¼˜åŒ–å™¨ï¼šéšæœºæ¢¯åº¦ä¸‹é™(SGD)ï¼Œç”¨æ¥æ›´æ–°æ¨¡å‹å‚æ•°
    optimizer = optim.SGD(model.parameters(), lr=0.01)
    print("ä¼˜åŒ–å™¨ï¼šéšæœºæ¢¯åº¦ä¸‹é™(SGD)ï¼Œå­¦ä¹ ç‡=0.01")
    
    # ========================================
    # ç¬¬5éƒ¨åˆ†ï¼šè®­ç»ƒæ¨¡å‹
    # ========================================
    print("\nğŸ“š ç¬¬5éƒ¨åˆ†ï¼šè®­ç»ƒæ¨¡å‹")
    print("-" * 30)
    
    # è®°å½•è®­ç»ƒè¿‡ç¨‹
    num_epochs = 1000  # è®­ç»ƒ1000è½®
    losses = []  # è®°å½•æ¯è½®çš„æŸå¤±
    
    print(f"å¼€å§‹è®­ç»ƒï¼Œå…±{num_epochs}è½®...")
    
    for epoch in range(num_epochs):
        # å‰å‘ä¼ æ’­ï¼šè®¡ç®—é¢„æµ‹å€¼
        predictions = model(x)
        
        # è®¡ç®—æŸå¤±
        loss = criterion(predictions, y)
        
        # åå‘ä¼ æ’­ï¼šè®¡ç®—æ¢¯åº¦
        optimizer.zero_grad()  # æ¸…é›¶ä¹‹å‰çš„æ¢¯åº¦
        loss.backward()        # è®¡ç®—æ–°çš„æ¢¯åº¦
        optimizer.step()       # æ›´æ–°å‚æ•°
        
        # è®°å½•æŸå¤±
        losses.append(loss.item())
        
        # æ¯100è½®æ‰“å°ä¸€æ¬¡ç»“æœ
        if (epoch + 1) % 100 == 0:
            print(f"ç¬¬{epoch+1}è½®ï¼ŒæŸå¤±ï¼š{loss.item():.4f}")
    
    # ========================================
    # ç¬¬6éƒ¨åˆ†ï¼šæŸ¥çœ‹è®­ç»ƒç»“æœ
    # ========================================
    print("\nğŸ“š ç¬¬6éƒ¨åˆ†ï¼šè®­ç»ƒç»“æœ")
    print("-" * 30)
    
    # æŸ¥çœ‹å­¦åˆ°çš„å‚æ•°
    learned_params = list(model.parameters())
    learned_w = learned_params[0].item()
    learned_b = learned_params[1].item()
    
    print(f"çœŸå®å‚æ•°ï¼šw={true_w}, b={true_b}")
    print(f"å­¦åˆ°å‚æ•°ï¼šw={learned_w:.4f}, b={learned_b:.4f}")
    print(f"å‚æ•°è¯¯å·®ï¼šwè¯¯å·®={abs(learned_w-true_w):.4f}, bè¯¯å·®={abs(learned_b-true_b):.4f}")
    
    # ========================================
    # ç¬¬7éƒ¨åˆ†ï¼šå¯è§†åŒ–ç»“æœ
    # ========================================
    print("\nğŸ“š ç¬¬7éƒ¨åˆ†ï¼šå¯è§†åŒ–è®­ç»ƒç»“æœ")
    print("-" * 30)
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    # åˆ›å»ºå›¾è¡¨
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # å·¦å›¾ï¼šæ•°æ®ç‚¹å’Œæ‹Ÿåˆç›´çº¿
    model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    with torch.no_grad():
        # ç”Ÿæˆä¸€äº›æµ‹è¯•ç‚¹æ¥ç”»ç›´çº¿
        x_test = torch.linspace(-4, 4, 100).reshape(-1, 1)
        y_test = model(x_test)
        
        # ç”»æ•°æ®ç‚¹
        ax1.scatter(x.numpy(), y.numpy(), alpha=0.6, label='è®­ç»ƒæ•°æ®', color='blue')
        # ç”»æ‹Ÿåˆç›´çº¿
        ax1.plot(x_test.numpy(), y_test.numpy(), 'r-', linewidth=2, 
                label=f'å­¦åˆ°çš„ç›´çº¿: y={learned_w:.2f}x+{learned_b:.2f}')
        # ç”»çœŸå®ç›´çº¿
        y_true_line = true_w * x_test + true_b
        ax1.plot(x_test.numpy(), y_true_line.numpy(), 'g--', linewidth=2,
                label=f'çœŸå®ç›´çº¿: y={true_w}x+{true_b}')
    
    ax1.set_xlabel('x')
    ax1.set_ylabel('y')
    ax1.set_title('çº¿æ€§å›å½’ç»“æœ')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # å³å›¾ï¼šè®­ç»ƒæŸå¤±æ›²çº¿
    ax2.plot(losses, color='orange', linewidth=2)
    ax2.set_xlabel('è®­ç»ƒè½®æ•°')
    ax2.set_ylabel('æŸå¤±å€¼')
    ax2.set_title('è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±å˜åŒ–')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('pytorch_demo/linear_regression_result.png', dpi=150, bbox_inches='tight')
    print("âœ… å›¾è¡¨å·²ä¿å­˜ä¸º 'linear_regression_result.png'")
    
    try:
        plt.show()
    except:
        print("ğŸ’¡ å¦‚æœæ— æ³•æ˜¾ç¤ºå›¾è¡¨ï¼Œè¯·æŸ¥çœ‹ä¿å­˜çš„PNGæ–‡ä»¶")
    
    # ========================================
    # ç¬¬8éƒ¨åˆ†ï¼šæµ‹è¯•æ¨¡å‹
    # ========================================
    print("\nğŸ“š ç¬¬8éƒ¨åˆ†ï¼šç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹")
    print("-" * 30)
    
    # æµ‹è¯•å‡ ä¸ªæ–°çš„è¾“å…¥
    test_inputs = torch.tensor([[0.0], [1.0], [2.0], [-1.0]])
    
    model.eval()
    with torch.no_grad():
        predictions = model(test_inputs)
        
        print("æ–°æ•°æ®é¢„æµ‹æµ‹è¯•ï¼š")
        for i, (input_val, pred_val) in enumerate(zip(test_inputs, predictions)):
            true_val = true_w * input_val + true_b
            print(f"è¾“å…¥: {input_val.item():4.1f} -> é¢„æµ‹: {pred_val.item():6.3f}, çœŸå®: {true_val.item():6.3f}")
    
    # ========================================
    # ç»ƒä¹ æ—¶é—´ï¼
    # ========================================
    print("\nğŸ¯ ç»ƒä¹ æ—¶é—´ï¼")
    print("-" * 30)
    print("å°è¯•ä¿®æ”¹è¿™ä¸ªæ–‡ä»¶ä¸­çš„å‚æ•°ï¼š")
    print("1. æ”¹å˜true_wå’Œtrue_bçš„å€¼ï¼Œçœ‹çœ‹èƒ½å¦å­¦åˆ°æ–°çš„å…³ç³»")
    print("2. è°ƒæ•´å­¦ä¹ ç‡(lr)ï¼Œçœ‹çœ‹è®­ç»ƒé€Ÿåº¦çš„å˜åŒ–")
    print("3. æ”¹å˜è®­ç»ƒè½®æ•°(num_epochs)")
    print("4. è°ƒæ•´å™ªå£°çš„å¤§å°ï¼Œçœ‹çœ‹å¯¹è®­ç»ƒçš„å½±å“")
    
    print("\nâœ… æ­å–œï¼æ‚¨å·²ç»å®Œæˆäº†çº¿æ€§å›å½’çš„å­¦ä¹ ï¼")
    print("ğŸ’¡ ä¸‹ä¸€æ­¥ï¼šè¿è¡Œ 03_neural_network_demo.py å­¦ä¹ ç¥ç»ç½‘ç»œ")

if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–
    try:
        import torch
        import matplotlib.pyplot as plt
        print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
        main()
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–åŒ…: {e}")
        print("è¯·è¿è¡Œ: pip install torch matplotlib") 