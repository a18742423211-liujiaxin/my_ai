#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¥ç»ç½‘ç»œåˆ†ç±»ç¤ºä¾‹
===============

è¿™ä¸ªæ–‡ä»¶å°†æ•™æ‚¨ï¼š
1. ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œ
2. å¦‚ä½•æ„å»ºå¤šå±‚ç¥ç»ç½‘ç»œ
3. å¦‚ä½•å¤„ç†åˆ†ç±»é—®é¢˜
4. ä»€ä¹ˆæ˜¯æ¿€æ´»å‡½æ•°
5. å¦‚ä½•è¯„ä¼°æ¨¡å‹æ€§èƒ½

ä»çº¿æ€§å›å½’è¿›é˜¶åˆ°ç¥ç»ç½‘ç»œï¼
"""

import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

def main():
    print("ğŸš€ æ¬¢è¿æ¥åˆ°ç¥ç»ç½‘ç»œå­¦ä¹ ï¼")
    print("=" * 50)
    
    # ========================================
    # ç¬¬1éƒ¨åˆ†ï¼šç†è§£ç¥ç»ç½‘ç»œ
    # ========================================
    print("\nğŸ“š ç¬¬1éƒ¨åˆ†ï¼šä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œï¼Ÿ")
    print("-" * 30)
    print("ç¥ç»ç½‘ç»œå°±åƒå¤§è„‘ä¸­çš„ç¥ç»å…ƒç½‘ç»œ")
    print("æ¯ä¸ªç¥ç»å…ƒæ¥æ”¶è¾“å…¥ï¼Œè¿›è¡Œè®¡ç®—ï¼Œç„¶åè¾“å‡ºç»“æœ")
    print("å¤šä¸ªç¥ç»å…ƒå±‚å±‚è¿æ¥ï¼Œå°±å½¢æˆäº†ç¥ç»ç½‘ç»œ")
    print("ç›¸æ¯”çº¿æ€§å›å½’ï¼Œç¥ç»ç½‘ç»œå¯ä»¥å­¦ä¹ æ›´å¤æ‚çš„æ¨¡å¼")
    
    # ========================================
    # ç¬¬2éƒ¨åˆ†ï¼šç”Ÿæˆåˆ†ç±»æ•°æ®
    # ========================================
    print("\nğŸ“š ç¬¬2éƒ¨åˆ†ï¼šç”Ÿæˆåˆ†ç±»æ•°æ®")
    print("-" * 30)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    
    # ç”Ÿæˆ2ç»´åˆ†ç±»æ•°æ®
    X, y = make_classification(
        n_samples=1000,      # 1000ä¸ªæ ·æœ¬
        n_features=2,        # 2ä¸ªç‰¹å¾(x1, x2)
        n_redundant=0,       # æ— å†—ä½™ç‰¹å¾
        n_informative=2,     # 2ä¸ªä¿¡æ¯ç‰¹å¾
        n_clusters_per_class=1,  # æ¯ç±»1ä¸ªèšç±»
        random_state=42
    )
    
    # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # è½¬æ¢ä¸ºPyTorchå¼ é‡
    X_train = torch.FloatTensor(X_train)
    X_test = torch.FloatTensor(X_test)
    y_train = torch.LongTensor(y_train)
    y_test = torch.LongTensor(y_test)
    
    print(f"è®­ç»ƒé›†å¤§å°: {X_train.shape[0]} ä¸ªæ ·æœ¬")
    print(f"æµ‹è¯•é›†å¤§å°: {X_test.shape[0]} ä¸ªæ ·æœ¬")
    print(f"ç‰¹å¾ç»´åº¦: {X_train.shape[1]} ä¸ªç‰¹å¾")
    print(f"ç±»åˆ«: {torch.unique(y_train).tolist()} (0å’Œ1ä¸¤ç±»)")
    
    # ========================================
    # ç¬¬3éƒ¨åˆ†ï¼šå¯è§†åŒ–æ•°æ®
    # ========================================
    print("\nğŸ“š ç¬¬3éƒ¨åˆ†ï¼šå¯è§†åŒ–æ•°æ®åˆ†å¸ƒ")
    print("-" * 30)
    
    plt.figure(figsize=(12, 4))
    
    # è®­ç»ƒæ•°æ®å¯è§†åŒ–
    plt.subplot(1, 3, 1)
    colors = ['red', 'blue']
    for i, color in enumerate(colors):
        mask = y_train == i
        plt.scatter(X_train[mask, 0], X_train[mask, 1], 
                   c=color, label=f'ç±»åˆ« {i}', alpha=0.7)
    plt.xlabel('ç‰¹å¾1')
    plt.ylabel('ç‰¹å¾2')
    plt.title('è®­ç»ƒæ•°æ®åˆ†å¸ƒ')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # ========================================
    # ç¬¬4éƒ¨åˆ†ï¼šå®šä¹‰ç¥ç»ç½‘ç»œ
    # ========================================
    print("\nğŸ“š ç¬¬4éƒ¨åˆ†ï¼šæ„å»ºç¥ç»ç½‘ç»œ")
    print("-" * 30)
    
    class SimpleNeuralNetwork(nn.Module):
        def __init__(self, input_size, hidden_size, output_size):
            super(SimpleNeuralNetwork, self).__init__()
            # ç¬¬ä¸€å±‚ï¼šè¾“å…¥å±‚åˆ°éšè—å±‚
            self.layer1 = nn.Linear(input_size, hidden_size)
            # æ¿€æ´»å‡½æ•°ï¼šReLU (Rectified Linear Unit)
            self.relu = nn.ReLU()
            # ç¬¬äºŒå±‚ï¼šéšè—å±‚åˆ°è¾“å‡ºå±‚
            self.layer2 = nn.Linear(hidden_size, output_size)
        
        def forward(self, x):
            # å‰å‘ä¼ æ’­è¿‡ç¨‹
            x = self.layer1(x)     # çº¿æ€§å˜æ¢
            x = self.relu(x)       # æ¿€æ´»å‡½æ•°
            x = self.layer2(x)     # è¾“å‡ºå±‚
            return x
    
    # åˆ›å»ºç½‘ç»œ
    input_size = 2    # 2ä¸ªè¾“å…¥ç‰¹å¾
    hidden_size = 10  # éšè—å±‚10ä¸ªç¥ç»å…ƒ
    output_size = 2   # 2ä¸ªè¾“å‡ºç±»åˆ«
    
    model = SimpleNeuralNetwork(input_size, hidden_size, output_size)
    
    print(f"ç½‘ç»œç»“æ„:")
    print(f"è¾“å…¥å±‚: {input_size} ä¸ªç¥ç»å…ƒ")
    print(f"éšè—å±‚: {hidden_size} ä¸ªç¥ç»å…ƒ (ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°)")
    print(f"è¾“å‡ºå±‚: {output_size} ä¸ªç¥ç»å…ƒ")
    print(f"æ€»å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
    
    # ========================================
    # ç¬¬5éƒ¨åˆ†ï¼šå®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    # ========================================
    print("\nğŸ“š ç¬¬5éƒ¨åˆ†ï¼šå®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨")
    print("-" * 30)
    
    # åˆ†ç±»é—®é¢˜ä½¿ç”¨äº¤å‰ç†µæŸå¤±
    criterion = nn.CrossEntropyLoss()
    print("æŸå¤±å‡½æ•°ï¼šäº¤å‰ç†µæŸå¤±(CrossEntropyLoss)")
    
    # ä½¿ç”¨Adamä¼˜åŒ–å™¨
    optimizer = optim.Adam(model.parameters(), lr=0.01)
    print("ä¼˜åŒ–å™¨ï¼šAdamï¼Œå­¦ä¹ ç‡=0.01")
    
    # ========================================
    # ç¬¬6éƒ¨åˆ†ï¼šè®­ç»ƒç¥ç»ç½‘ç»œ
    # ========================================
    print("\nğŸ“š ç¬¬6éƒ¨åˆ†ï¼šè®­ç»ƒç¥ç»ç½‘ç»œ")
    print("-" * 30)
    
    num_epochs = 500
    train_losses = []
    train_accuracies = []
    
    print(f"å¼€å§‹è®­ç»ƒï¼Œå…±{num_epochs}è½®...")
    
    for epoch in range(num_epochs):
        # è®­ç»ƒæ¨¡å¼
        model.train()
        
        # å‰å‘ä¼ æ’­
        outputs = model(X_train)
        loss = criterion(outputs, y_train)
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # è®¡ç®—å‡†ç¡®ç‡
        with torch.no_grad():
            _, predicted = torch.max(outputs, 1)
            accuracy = (predicted == y_train).float().mean().item()
        
        # è®°å½•è®­ç»ƒè¿‡ç¨‹
        train_losses.append(loss.item())
        train_accuracies.append(accuracy)
        
        # æ¯50è½®æ‰“å°ä¸€æ¬¡ç»“æœ
        if (epoch + 1) % 50 == 0:
            print(f"ç¬¬{epoch+1:3d}è½®ï¼ŒæŸå¤±ï¼š{loss.item():.4f}ï¼Œå‡†ç¡®ç‡ï¼š{accuracy:.4f}")
    
    # ========================================
    # ç¬¬7éƒ¨åˆ†ï¼šè¯„ä¼°æ¨¡å‹
    # ========================================
    print("\nğŸ“š ç¬¬7éƒ¨åˆ†ï¼šè¯„ä¼°æ¨¡å‹æ€§èƒ½")
    print("-" * 30)
    
    # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
    model.eval()
    with torch.no_grad():
        test_outputs = model(X_test)
        test_loss = criterion(test_outputs, y_test)
        _, test_predicted = torch.max(test_outputs, 1)
        test_accuracy = (test_predicted == y_test).float().mean().item()
    
    print(f"æµ‹è¯•é›†ç»“æœï¼š")
    print(f"æŸå¤±ï¼š{test_loss.item():.4f}")
    print(f"å‡†ç¡®ç‡ï¼š{test_accuracy:.4f} ({test_accuracy*100:.1f}%)")
    
    # ========================================
    # ç¬¬8éƒ¨åˆ†ï¼šå¯è§†åŒ–ç»“æœ
    # ========================================
    print("\nğŸ“š ç¬¬8éƒ¨åˆ†ï¼šå¯è§†åŒ–è®­ç»ƒç»“æœ")
    print("-" * 30)
    
    # å†³ç­–è¾¹ç•Œå¯è§†åŒ–
    def plot_decision_boundary(model, X, y, title):
        h = 0.01
        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
        xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                            np.arange(y_min, y_max, h))
        
        mesh_points = torch.FloatTensor(np.c_[xx.ravel(), yy.ravel()])
        model.eval()
        with torch.no_grad():
            Z = model(mesh_points)
            _, Z = torch.max(Z, 1)
        Z = Z.reshape(xx.shape)
        
        plt.contourf(xx, yy, Z.numpy(), alpha=0.3, levels=1, colors=['lightcoral', 'lightblue'])
        
        colors = ['red', 'blue']
        for i, color in enumerate(colors):
            mask = y == i
            plt.scatter(X[mask, 0], X[mask, 1], c=color, label=f'ç±»åˆ« {i}', alpha=0.7)
        
        plt.xlabel('ç‰¹å¾1')
        plt.ylabel('ç‰¹å¾2')
        plt.title(title)
        plt.legend()
        plt.grid(True, alpha=0.3)
    
    # æµ‹è¯•æ•°æ®å’Œå†³ç­–è¾¹ç•Œ
    plt.subplot(1, 3, 2)
    plot_decision_boundary(model, X_test.numpy(), y_test.numpy(), 
                          f'æµ‹è¯•é›†é¢„æµ‹ç»“æœ\nå‡†ç¡®ç‡: {test_accuracy:.3f}')
    
    # è®­ç»ƒè¿‡ç¨‹
    plt.subplot(1, 3, 3)
    epochs_range = range(1, num_epochs + 1)
    plt.plot(epochs_range, train_losses, 'b-', label='è®­ç»ƒæŸå¤±', alpha=0.8)
    plt.xlabel('è®­ç»ƒè½®æ•°')
    plt.ylabel('æŸå¤±å€¼')
    plt.title('è®­ç»ƒè¿‡ç¨‹')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('pytorch_demo/neural_network_result.png', dpi=150, bbox_inches='tight')
    print("âœ… å›¾è¡¨å·²ä¿å­˜ä¸º 'neural_network_result.png'")
    
    try:
        plt.show()
    except:
        print("ğŸ’¡ å¦‚æœæ— æ³•æ˜¾ç¤ºå›¾è¡¨ï¼Œè¯·æŸ¥çœ‹ä¿å­˜çš„PNGæ–‡ä»¶")
    
    # ========================================
    # ç¬¬9éƒ¨åˆ†ï¼šç†è§£æ¿€æ´»å‡½æ•°
    # ========================================
    print("\nğŸ“š ç¬¬9éƒ¨åˆ†ï¼šç†è§£æ¿€æ´»å‡½æ•°")
    print("-" * 30)
    
    # å±•ç¤ºä¸åŒæ¿€æ´»å‡½æ•°çš„æ•ˆæœ
    x = torch.linspace(-5, 5, 100)
    relu = torch.relu(x)
    sigmoid = torch.sigmoid(x)
    tanh = torch.tanh(x)
    
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 3, 1)
    plt.plot(x.numpy(), relu.numpy(), 'r-', linewidth=2, label='ReLU')
    plt.xlabel('è¾“å…¥')
    plt.ylabel('è¾“å‡º')
    plt.title('ReLUæ¿€æ´»å‡½æ•°')
    plt.grid(True, alpha=0.3)
    plt.legend()
    
    plt.subplot(1, 3, 2)
    plt.plot(x.numpy(), sigmoid.numpy(), 'g-', linewidth=2, label='Sigmoid')
    plt.xlabel('è¾“å…¥')
    plt.ylabel('è¾“å‡º')
    plt.title('Sigmoidæ¿€æ´»å‡½æ•°')
    plt.grid(True, alpha=0.3)
    plt.legend()
    
    plt.subplot(1, 3, 3)
    plt.plot(x.numpy(), tanh.numpy(), 'b-', linewidth=2, label='Tanh')
    plt.xlabel('è¾“å…¥')
    plt.ylabel('è¾“å‡º')
    plt.title('Tanhæ¿€æ´»å‡½æ•°')
    plt.grid(True, alpha=0.3)
    plt.legend()
    
    plt.tight_layout()
    plt.savefig('pytorch_demo/activation_functions.png', dpi=150, bbox_inches='tight')
    print("âœ… æ¿€æ´»å‡½æ•°å›¾è¡¨å·²ä¿å­˜ä¸º 'activation_functions.png'")
    
    try:
        plt.show()
    except:
        print("ğŸ’¡ å¦‚æœæ— æ³•æ˜¾ç¤ºå›¾è¡¨ï¼Œè¯·æŸ¥çœ‹ä¿å­˜çš„PNGæ–‡ä»¶")
    
    print("\næ¿€æ´»å‡½æ•°è¯´æ˜ï¼š")
    print("â€¢ ReLU: è´Ÿæ•°å˜0ï¼Œæ­£æ•°ä¸å˜ï¼Œæœ€å¸¸ç”¨")
    print("â€¢ Sigmoid: å‹ç¼©åˆ°0-1ä¹‹é—´ï¼Œç”¨äºæ¦‚ç‡è¾“å‡º")
    print("â€¢ Tanh: å‹ç¼©åˆ°-1åˆ°1ä¹‹é—´ï¼Œé›¶ç‚¹å¯¹ç§°")
    
    # ========================================
    # ç»ƒä¹ æ—¶é—´ï¼
    # ========================================
    print("\nğŸ¯ ç»ƒä¹ æ—¶é—´ï¼")
    print("-" * 30)
    print("å°è¯•ä¿®æ”¹è¿™ä¸ªæ–‡ä»¶ä¸­çš„å‚æ•°ï¼š")
    print("1. æ”¹å˜éšè—å±‚ç¥ç»å…ƒæ•°é‡(hidden_size)")
    print("2. å°è¯•ä¸åŒçš„æ¿€æ´»å‡½æ•°(sigmoid, tanh)")
    print("3. è°ƒæ•´å­¦ä¹ ç‡å’Œè®­ç»ƒè½®æ•°")
    print("4. æ·»åŠ æ›´å¤šéšè—å±‚")
    print("5. æ”¹å˜æ•°æ®é›†çš„å¤æ‚åº¦")
    
    print("\nâœ… æ­å–œï¼æ‚¨å·²ç»å®Œæˆäº†ç¥ç»ç½‘ç»œçš„å­¦ä¹ ï¼")
    print("ğŸ‰ æ‚¨ç°åœ¨å·²ç»æŒæ¡äº†PyTorchçš„åŸºç¡€çŸ¥è¯†ï¼")

if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–
    try:
        import torch
        import matplotlib.pyplot as plt
        import sklearn
        print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"âœ… Scikit-learnç‰ˆæœ¬: {sklearn.__version__}")
        main()
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–åŒ…: {e}")
        print("è¯·è¿è¡Œ: pip install torch matplotlib scikit-learn") 